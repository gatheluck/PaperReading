% 2018/01/09
% shape-bias vs texture-bias
@article{
    gilmer2018adversarial,
    title={Adversarial Spheres},
    author={Justin Gilmer and Luke Metz and Fartash Faghri and Samuel S. Schoenholz and Maithra Raghu and Martin Wattenberg and Ian Goodfellow},
    journal=arXiv # "1801.02774",
    year={2018}
}

% 2018/04/30
@inproceedings{
    schmidt2018adversarially,
    title={Adversarially Robust Generalization Requires More Data},
    author={Ludwig Schmidt and Shibani Santurkar and Dimitris Tsipras and Kunal Talwar andAleksander MÄ…dry},
    booktitle=NeurIPS,
    year={2018}
}

% 2018/05/30
@inproceedings{
    tsipras2018robustness,
    title={Robustness may be at odds with accuracy},
    author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
    booktitle=ICLR,
    year={2019}
}

% 2018/08/05
@inproceedings{
    su2018is,
    title={Is Robustness the Cost of Accuracy? -- A Comprehensive Study on the Robustness of 18 Deep Image Classification Models},
    author={Dong Su and Huan Zhang and Hongge Chen and Jinfeng Yi and Pin-Yu Chen and Yupeng Gao},
    booktitle=ECCV,
    year={2018}
}

% 2018/09/06
@inproceedings{
    shafahi2018are,
    title={Are adversarial examples inevitable?},
    author={Ali Shafahi and W. Ronny Huang and Christoph Studer and Soheil Feizi and Tom Goldstein},
    booktitle=ICLR,
    year={2019}
}

% 2018/11/29
@inproceedings{
    geirhos2018imagenet,
    title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
    author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
    booktitle=ICLR,
    year={2019}
}

% 2019/01/29
@inproceedings{
    ford2019Adversarial,
    title={Adversarial Examples Are a Natural Consequence of Test Error in Noise},
    author={Nic Ford and Justin Gilmer and Nicolas Carlini and Dogus Cubuk},
    booktitle=ICML,
    year={2019}
}

% 2019/05/06
@inproceedings{
    ilyas2019Adversarial,
    title={Adversarial Examples Are Not Bugs, They Are Features},
    author={Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Logan Engstrom and Brandon Tran, Aleksander Madry},
    booktitle=NeurIPS,
    year={2019}
}

% 2019/05/06
@inproceedings{
    galloway2019batch,
    title={Batch Normalization is a Cause of Adversarial Vulnerability},
    author={Angus Galloway and Anna Golubeva and Thomas Tanay and Medhat Moussa and Graham W. Taylor},
    booktitle=ICMLW,
    year={2019}
}

% 2019/05/19
@article{
    itazuri2019what,
    title={What Do Adversarially Robust Models Look At?},
    author={Takahiro Itazuri and Yoshihiro Fukuhara and Hirokatsu Kataoka and Shigeo Morishima},
    journal=arXiv # "1905.07666",
    year={2019}
}

% 2019/05/20
@inproceedings{
    brendel2019approximating,
    title={Approximating cnns with bag-of-local-features models works surprisingly well on imagenet},
    author={Brendel, Wieland and Bethge, Matthias},
    booktitle=ICLR,
    year={2019}
}

% 2019/05/23
@inproceedings{
    zhang2019interpreting,
    title={Interpreting adversarially trained convolutional neural networks},
    author={Zhang, Tianyuan and Zhu, Zhanxing},
    booktitle=ICML,
    year={2019}
}

% 2019/10/18
@inproceedings{
    kaur2019perceptually,
    title={Are Perceptually-Aligned Gradients a General Property of Robust Classifiers?},
    author={Kaur, Simran and Cohen, Jeremy and Lipton, Zachary C},
    booktitle=NeurIPSW,
    year={2019}
}

% 2019/11/20
% shape-bias vs texture-bias
@article{
    hermann2019exploring,
    title={Exploring the Origins and Prevalence of Texture Bias in Convolutional Neural Networks},
    author={Katherine L. Hermann and Simon Kornblith},
    journal=arXiv # "1911.09071",
    year={2019}
}