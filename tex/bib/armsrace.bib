% 2013/12/21
@inproceedings{
    szegedy2013intriguing,
    title={Intriguing properties of neural networks},
    author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
    booktitle=ICLR,
    year={2014}
}

% 2014/12/20
% FGSM, Adversarial Training
@inproceedings{
    goodfellow2015explaining,
    title={Explaining and Harnessing Adversarial Examples},
    author={Ian J. Goodfellow and Janathon Shlens and Christian Szegedy},
    booktitle=ICLR,
    year={2015}
}

% 2015/11/14
% DeepFool
@inproceedings{
    moosavi2016deepfool,
    title={Deepfool: a simple and accurate method to fool deep neural networks},
    author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
    booktitle=CVPR,
    year={2016}
}

% 2015/11/14
% Defensive Distillation
@inproceedings{
    papernot2016distillation,
    title={Distillation as a defense to adversarial perturbations against deep neural networks},
    author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
    booktitle=SP,
    pages={582--597},
    year={2016}
}

% 2015/11/24
% JSMA
@inproceedings{
    papernot2016limitations,
    title={The limitations of deep learning in adversarial settings},
    author={Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z Berkay and Swami, Ananthram},
    booktitle=ESP,
    pages={372--387},
    year={2016}
}

% 2016/05/24
@article{
    papernot2016transferability,
    title={Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples},
    author={Nicolas Papernot and Patrick McDaniel and Ian Goodfellow},
    journal=arXiv # "1605.072771",
    year={2016}
}

% 2016/07/08
% Iterative FGSM
@inproceedings{
    kurakin2017dversarial,
    title={Adversarial examples in the physical world},
    author={Alexey Kurakin and Ian Goodfellow and Samy Bengio},
    journal=ICLRW,
    year={2017}
}

% 2016/07/14
@article{
    carlini2016defensive,
    title={Defensive distillation is not robust to adversarial examples},
    author={Carlini, Nicholas and Wagner, David},
    journal=arXiv # "1607.04311",
    year={2016}
}

% 2016/08/01
% detection
@inproceedings{
    hendrycks2017early,
    title={Early Methods for Detecting Adversarial Images},
    author={Dan Hendrycks and Kevin Gimpel},
    booktitle=ICLRW,
    year={2017}
}

% 2016/08/16
% C&W attack
@inproceedings{
    carlini2017towards,
    title={Towards evaluating the robustness of neural networks},
    author={Carlini, Nicholas and Wagner, David},
    booktitle=SP,
    pages={39--57},
    year={2017}
}

% 2016/10/24
@inproceedings{
    sharif2016accessorize,
    title={Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition},
    author={Mahmood Sharif and Sruti Bhagavatula and Lujo Bauer and Michael K. Reiter},
    booktitle=SIGSAC,
    year={2016}
}

% 2016/10/26
% universal perturbation
@inproceedings{
    moosavi2017universal,
    title={Universal adversarial perturbations},
    author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
    booktitle=CVPR,
    pages={1765--1773},
    year={2017}
}

% 2016/11/08
@inproceedings{
    liu2017delving,
    title={Delving into Transferable Adversarial Examples and Black-box Attacks},
    author={Yanpei Liu and Xinyun Chen and Chang Liu and Dawn Song},
    booktitle=ICLR,
    year={2017}
}

% 2016/12/21
% detection
@inproceedings{
    li2017adversarial,
    title={Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics},
    author={Xin Li and Fuxin Li},
    booktitle=ICCV,
    pages={1765--1773},
    year={2017}
}

% 2017/02/21
% detection
@article{
    grosse2017on,
    title={On the (Statistical) Detection of Adversarial Examples},
    author={Kathrin Grosse and Praveen Manoharan and Nicolas Papernot and Michael Backes and Patrick McDaniel},
    journal=arXiv # "1702.06280",
    year={2017}
}

% 2017/03/01
% detection
@article{
    feinman2017detecting,
    title={Detecting Adversarial Samples from Artifacts},
    author={Reuben Feinman and Ryan R. Curtin and Saurabh Shintre and Andrew B. Gardner},
    journal=arXiv # "1703.00410",
    year={2017}
}

% 2017/04/17
% detection
@article{
    gong2017adversarial,
    title={Adversarial and Clean Data Are Not Twins},
    author={Zhitao Gong and Wenlu Wang and Wei-Shinn Ku},
    journal=arXiv # "1704.04960",
    year={2017}
}

% 2017/05/20
% not easy to detection
@article{
    carlini2017adversarial,
    title={Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods},
    author={Nicholas Carlini and David Wagner},
    journal=arXiv # "1705.07263",
    year={2017}
}

% 2017/06/19
% PGD, Adversarial Training
@inproceedings{
    madry2018towards,
    title={Towards Deep Learning Models Resistant to Adversarial Attacks},
    author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
    booktitle=ICLR,
    year={2018}
}

% 2017/07/24
% 3D AEs
@inproceedings{
    athalye2018synthesizing,
    title={Synthesizing Robust Adversarial Examples},
    author={Anish Athalye and Logan Engstrom and Andrew Ilyas and Kevin Kwok},
    booktitle=ICML,
    year={2018}
}

% 2017/07/27
% 3D AEs
@inproceedings{
    eykholt2018robust,
    title={Robust Physical-World Attacks on Deep Learning Models},
    author={Kevin Eykholt and Ivan Evtimov and Earlence Fernandes and Bo Li and Amir Rahmati and Chaowei Xiao and Atul Prakash and Tadayoshi Kohno and Dawn Song},
    booktitle=CVPR,
    year={2018}
}

% 2017/10/24
% one pixel attack
@article{
    su2017one,
    title={One pixel attack for fooling deep neural networks},
    author={Jiawei Su and Danilo Vasconcellos Vargas and Sakurai Kouichi},
    journal=arXiv # "1710.08864",
    year={2017}
}

% 2017/10/25
% mixup
@inproceedings{
    zhang2018mixup,
    title={mixup: Beyond Empirical Risk Minimization},
    author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
    booktitle=ICLR,
    year={2018}
}

% 2017/10/31
% GAN attack
@inproceedings{
    zhao2018generating,
    title={Generating Natural Adversarial Examples},
    author={Zhengli Zhao and Dheeru Dua and Sameer Singh},
    booktitle=ICLR,
    year={2018}
}

% 2017/10/30
@inproceedings{
    song2018pixeldefend,
    title={PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples},
    author={Yang Song and Taesup Kim and Sebastian Nowozin and Stefano Ermon and Nate Kushman},
    booktitle=ICLR,
    year={2018}
}

% 2017/10/31
@inproceedings{
    guo2018countering,
    title={Countering Adversarial Images using Input Transformations},
    author={Chuan Guo and Mayank Rana and Moustapha Cisse and Laurens van der Maaten},
    booktitle=ICLR,
    year={2018}
}

% 2017/11/02
@inproceedings{
    wong2018provable,
    title={Provable defenses against adversarial examples via the convex outer adversarial polytope},
    author={Eric Wong and J. Zico Kolter},
    booktitle=ICML,
    year={2018}
}

% 2017/11/06
@inproceedings{
    xie2018mitigating,
    title={Mitigating Adversarial Effects Through Randomization},
    author={Cihang Xie and Jianyu Wang and Zhishuai Zhang and Zhou Ren and Alan Yuille},
    booktitle=ICLR,
    year={2018}
}

% 2018/01/08
@inproceedings{
    ma2018characterizing,
    title={Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality},
    author={Xingjun Ma and Bo Li and Yisen Wang and Sarah M. Erfani and Sudanthi Wijewickrema and Grant Schoenebeck and Dawn Song and Michael E. Houle and James Bailey},
    booktitle=ICLR,
    year={2018}
}

% 2018/01/29
@inproceedings{
    raghunathan2018certified,
    title={Certified Defenses against Adversarial Examples},
    author={Aditi Raghunathan and Jacob Steinhardt and Percy Liang},
    booktitle=ICLR,
    year={2018}
}

% 2018/02/01
@inproceedings{
    athalye2018obfuscated,
    title={Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},
    author={Anish Athalye and Nicholas Carlini and David Wagner},
    booktitle=ICML,
    year={2018}
}

% 2018/02/16
@inproceedings{
    buckman2018thermometer,
    title={Thermometer Encoding: One Hot Way To Resist Adversarial Examples},
    author={Jacob Buckman and Aurko Roy and Colin Raffel and Ian Goodfellow},
    booktitle=ICLR,
    year={2018}
}

% 2018/04/30
@inproceedings{
    schmidt2018adversarially,
    title={Adversarially Robust Generalization Requires More Data},
    author={Ludwig Schmidt and Shibani Santurkar and Dimitris Tsipras and Kunal Talwar and Aleksander Mądry},
    booktitle=NIPS,
    year={2018}
}

% 2018/05/05
@inproceedings{
    dhillon2018stochastic,
    title={Stochastic Activation Pruning for Robust Adversarial Defense},
    author={Guneet S. Dhillon and Kamyar Azizzadenesheli and Zachary C. Lipton and Jeremy Bernstein and Jean Kossaifi and Aran Khanna and Anima Anandkumar},
    booktitle=ICLR,
    year={2018}
}

% 2018/05/17
@inproceedings{
    samangouei2018defense,
    title={Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models},
    author={Pouya Samangouei and Maya Kabkab and Rama Chellappa},
    booktitle=ICLR,
    year={2018}
}

% 2018/08/08
% attack by differenciable renderer
@inproceedings{
    liu2019beyond,
    title={Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer},
    author={Hsueh-Ti Derek Liu and Michael Tao and Chun-Liang Li and Derek Nowrouzezahrai and Alec Jacobson},
    booktitle=ICLR,
    year={2019}
}

% 2018/11/08
@inproceedings{
    tramer2019adversarial,
    title={AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning},
    author={Florian Tramèr and Pascal Dupré and Gili Rusak and Giancarlo Pellegrino and Dan Boneh},
    booktitle=SIGSAC,
    year={2019}
}

% 2018/12/09
@inproceedings{
    xie2019feature,
    title={Feature Denoising for Improving Adversarial Robustness},
    author={Cihang Xie and Yuxin Wu and Laurens van der Maaten and Alan Yuille and Kaiming He},
    booktitle=CVPR,
    year={2019}
}

% 2019/01/24
@inproceedings{
    zhang2019theoretically,
    title={Theoretically Principled Trade-off between Robustness and Accuracy},
    author={Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric P. Xing and Laurent El Ghaoui and Michael I. Jordan},
    booktitle=ICML,
    year={2019}
}

% 2019/02/18
@article{
    carlini2019on,
    title={On Evaluating Adversarial Robustness},
    author={Nicholas Carlini and Anish Athalye and Nicolas Papernot and Wieland Brendel and Jonas Rauber, Dimitris Tsipras and Ian Goodfellow and Aleksander Madry and Alexey Kurakin},
    journal=arXiv # "1902.06705",
    year={2019}
}

% 2019/03/25
% 
@inproceedings{
    jacobsen2019exploiting,
    title={Exploiting Excessive Invariance caused by Norm-Bounded Adversarial Robustness},
    author={Jörn-Henrik Jacobsen and Jens Behrmannn and Nicholas Carlini and Florian Tramèr and Nicolas Papernot},
    booktitle=ICLRW,
    year={2019}
}

% 2019/04/29
% Free Adversarial Training
@inproceedings{
    shafahi2019adversarial,
    title={Adversarial Training for Free!},
    author={Ali Shafahi and Mahyar Najibi and Amin Ghiasi and Zheng Xu and John Dickerson and Christoph Studer and Larry S. Davis and Gavin Taylor and Tom Goldstein},
    booktitle=NeurIPS,
    year={2019}
}

% 2019/05/02
% YOPO
@inproceedings{
    zhang2019you,
    title={You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle},
    author={Dinghuai Zhang, Tianyuan Zhang, Yiping Lu, Zhanxing Zhu, Bin Dong},
    booktitle=NeurIPS,
    year={2019}
}

% 2019/05/14
% dynamic attack
@inproceedings{
    goodfellow2019a,
    title={A Research Agenda: Dynamic Models to Defend Against Correlated Attacks},
    author={Ian Goodfellow},
    booktitle=ICLR,
    year={2019}
}

% 2019/05/24
@inproceedings{
    najafi2019robustness,
    title={Robustness to Adversarial Perturbations in Learning from Incomplete Data},
    author={Amir Najafi and Shin-ichi Maeda and Masanori Koyama and Takeru Miyato},
    booktitle=NeurIPS,
    year={2019}
}

% 2019/05/25
% k-WTA
@inproceedings{
    xiao2020enhancing,
    title={Enhancing Adversarial Defense by k-Winners-Take-All},
    author={Chang Xiao and Peilin Zhong and Changxi Zheng},
    booktitle=ICLR,
    year={2020}
}

% 2019/05/31
@inproceedings{
    uesato2019are,
    title={Are Labels Required for Improving Adversarial Robustness?},
    author={Jonathan Uesato and Jean-Baptiste Alayrac and Po-Sen Huang and Robert Stanforth, Alhussein Fawzi and Pushmeet Kohli},
    booktitle=NeurIPS,
    year={2019}
}

% 2019/06/28
% AT + Rotation estimation
@inproceedings{
    hendrycks2019using,
    title={Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty},
    author={Dan Hendrycks and Mantas Mazeika and Saurav Kadavath and Dawn Song},
    booktitle=NeurIPS,
    year={2019}
}

% 2019/08/21
% UAR
@article{
    kang2019testing,
    title={Testing robustness against unforeseen adversaries},
    author={Kang, Daniel and Sun, Yi and Hendrycks, Dan and Brown, Tom and Steinhardt, Jacob},
    journal=arXiv # "1908.08016",
    year={2019}
}

% 2019/09/23
@inproceedings{
    song2020robust,
    title={Robust Local Features for Improving the Generalization of Adversarial Training},
    author={Chuanbiao Song and Kun He and Jiadong Lin and Liwei Wang and John E. Hopcroft},
    booktitle=ICLR,
    year={2020}
}

% 2019/11/21
@inproceedings{
    xie2020adversarial,
    title={Adversarial Examples Improve Image Recognition},
    author={Cihang Xie and Mingxing Tan and Boqing Gong and Jiang Wang and Alan Yuille and Quoc V. Le},
    booktitle=CVPR,
    year={2020}
}

% 2019/11/29
% Square Attack
@article{
    andriushchenko2019square,
    title={Square Attack: a query-efficient black-box adversarial attack via random search},
    author={Maksym Andriushchenko and Francesco Croce and Nicolas Flammarion and Matthias Hein},
    journal=arXiv # "1912.00049",
    year={2019}
}

% 2020/01/12
@inproceedings{
    wong2020fast,
    title={Fast is better than free: Revisiting adversarial training},
    author={Eric Wong and Leslie Rice and J. Zico Kolter},
    booktitle=ICLR,
    year={2020}
}

% 2020/02/11
@article{
    tramer2020fundamental,
    title={Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations},
    author={Florian Tramèr and Jens Behrmann and Nicholas Carlini and Nicolas Papernot and Jörn-Henrik Jacobsen},
    journal=arXiv # "2002.04599",
    year={2020}
}

% 2020/03/03
@article{
    croce2020reliable,
    title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
    author={Croce, Francesco and Hein, Matthias},
    journal=arXiv # "2003.01690",
    year={2020}
}

% 2020/04/01
@inproceedings{
    addepalli2020towards,
    title={Towards Achieving Adversarial Robustness by Enforcing Feature Consistency Across Bit Planes},
    author={Sravanti Addepalli and Vivek B.S. and Arya Baburaj and Gaurang Sriramanan and R. Venkatesh Babu},
    booktitle=CVPR,
    year={2020}
}

% 2020/03/05
@inproceedings{
    lee2020adversarial,
    title={Adversarial Vertex Mixup: Toward Better Adversarially Robust Generalization},
    author={Saehyung Lee, Hyungyu Lee, Sungroh Yoon},
    booktitle=CVPR,
    year={2020}
}

% 2020/03/19
% shadow attack
@article{
    ghiasi2020breaking,
    title={Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates},
    author={Amin Ghiasi and Ali Shafahi and Tom Goldstein},
    journal=arXiv # "2003.08937",
    year={2020}
}

% 2020/03/28
% AT + self supervised learning
@inproceedings{
    chen2020adversarial,
    title={Adversarial Robustness: From Self-Supervised Pre-Training to Fine-Tuning},
    author={Tianlong Chen and Sijia Liu and Shiyu Chang and Yu Cheng and Lisa Amini and Zhangyang Wang},
    booktitle=CVPR,
    year={2020}
}